{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "import random\n",
    "import string\n",
    "\n",
    "#生成验证码\n",
    "characters = string.digits+string.ascii_letters\n",
    "def random_captcha_text(char_set=characters, captcha_size=4):\n",
    "    captcha_text = []\n",
    "    for i in range(captcha_size):\n",
    "        c = random.choice(char_set)\n",
    "        captcha_text.append(c)\n",
    "    return captcha_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成完毕\n"
     ]
    }
   ],
   "source": [
    "def gen_captcha_text_and_image():\n",
    "    image = ImageCaptcha(width=160, height=60) \n",
    "    captcha_text = random_captcha_text()\n",
    "    captcha_text = ''.join(captcha_text)\n",
    "    captcha = image.generate(captcha_text)\n",
    "    image.write(captcha_text, 'captcha/' + captcha_text + '.jpg')\n",
    "num = 10\n",
    "for i in range(num):\n",
    "    gen_captcha_text_and_image()\n",
    "print(\"生成完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense,GlobalAvgPool2D,Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,ReduceLROnPlateau\n",
    "import string\n",
    "import numpy as np\n",
    "import os\n",
    "from plot_model import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符包含所有数字和所有小写英文字母，一共62个\n",
    "characters = string.digits + string.ascii_letters\n",
    "# 类别数62\n",
    "num_classes = len(characters)\n",
    "# 批次大小\n",
    "batch_size = 64\n",
    "# 周期数\n",
    "epochs=100\n",
    "# 训练集数据，大约50000张图片\n",
    "# 事先用captcha模块生成，长度都是4\n",
    "train_dir = \"./captcha/train/\"\n",
    "# 测试集数据，大约10000张图片\n",
    "# 事先用captcha模块生成，长度都是4\n",
    "test_dir = \"./captcha/test/\"\n",
    "# 图片宽度\n",
    "width=160\n",
    "# 图片高度\n",
    "height=60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有验证码图片路径和标签\n",
    "def get_filenames_and_classes(dataset_dir):\n",
    "    # 存放图片路径\n",
    "    photo_filenames = []\n",
    "    # 存放图片标签\n",
    "    y = []\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        # 获取文件完整路径\n",
    "        path = os.path.join(dataset_dir, filename)\n",
    "        # 保存图片路径\n",
    "        photo_filenames.append(path)\n",
    "        # 取文件名前4位，也就是验证码的标签\n",
    "        captcha_text = filename[0:4]\n",
    "        # 定义一个空label\n",
    "        label = np.zeros((4, num_classes), dtype=np.uint8)\n",
    "        # 标签转独热编码\n",
    "        for i, ch in enumerate(captcha_text):\n",
    "            # 设置标签，独热编码one-hot格式\n",
    "            # characters.find(ch)得到ch在characters中的位置，可以理解为ch的编号\n",
    "            label[i, characters.find(ch)] = 1\n",
    "        # 保存独热编码的标签\n",
    "        y.append(label)\n",
    "    # 返回图片路径和标签\n",
    "    return np.array(photo_filenames),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练集图片路径和标签\n",
    "x_train,y_train = get_filenames_and_classes(train_dir)\n",
    "\n",
    "# 获取测试集图片路径和标签\n",
    "x_test,y_test = get_filenames_and_classes(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像处理函数\n",
    "# 获得每一条数据的图片路径和标签\n",
    "def image_function(filenames, label):\n",
    "    # 根据图片路径读取图片内容\n",
    "    image = tf.io.read_file(filenames)\n",
    "    # 将图像解码为jpeg格式的3维数据\n",
    "    image = tf.image.decode_jpeg(image, channels=3)   \n",
    "    # 归一化\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # 返回图片数据和标签\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签处理函数\n",
    "# 获得每一个批次的图片数据和标签\n",
    "def label_function(image, label):\n",
    "    # transpose改变数据的维度，比如原来的数据shape是(64,4,62)\n",
    "    # 这里的64是批次大小，验证码长度为4有4个标签，62是62个不同的字符\n",
    "    # tf.transpose(label,[1,0,2])计算后得到的shape为(4,64,62)\n",
    "    # 原来的第1个维度变成了第0维度，原来的第0维度变成了1维度，第2维不变\n",
    "    # (64,4,62)->(4,64,62)\n",
    "    label = tf.transpose(label,[1,0,2])\n",
    "    # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义4个任务，所以这里返回4个标签\n",
    "    # 每个标签的shape为(64,62)，64是批次大小，62是独热编码格式的标签\n",
    "    return image, (label[0],label[1],label[2],label[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建dataset对象，传入训练集图片路径和标签\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# 打乱数据，buffer_size定义数据缓冲器大小，随意设置一个较大的值\n",
    "# reshuffle_each_iteration=True，每次迭代都会随机打乱\n",
    "dataset_train = dataset_train.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\n",
    "# map-可以自定义一个函数来处理每一条数据\n",
    "dataset_train = dataset_train.map(image_function)\n",
    "# 数据重复生成1个周期\n",
    "dataset_train = dataset_train.repeat(1)\n",
    "# 定义批次大小\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "# 注意这个map和前面的map有所不同，第一个map在batch之前，所以是处理每一条数据\n",
    "# 这个map在batch之后，所以是处理每一个batch的数据\n",
    "dataset_train = dataset_train.map(label_function)\n",
    "\n",
    "# 创建dataset对象，传入测试集图片路径和标签\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "# 打乱数据，buffer_size定义数据缓冲器大小，随意设置一个较大的值\n",
    "# reshuffle_each_iteration=True，每次迭代都会随机打乱\n",
    "dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\n",
    "# map-可以自定义一个函数来处理每一条数据\n",
    "dataset_test = dataset_test.map(image_function)\n",
    "# 数据重复生成1个周期\n",
    "dataset_test = dataset_test.repeat(1)\n",
    "# 定义批次大小\n",
    "dataset_test = dataset_test.batch(batch_size)\n",
    "# 注意这个map和前面的map有所不同，第一个map在batch之前，所以是处理每一条数据\n",
    "# 这个map在batch之后，所以是处理每一个batch的数据\n",
    "dataset_test = dataset_test.map(label_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 160, 3)\n",
      "(4, 64, 62)\n"
     ]
    }
   ],
   "source": [
    "# 生成一个批次的数据和标签\n",
    "# 可以用于查看数据和标签的情况\n",
    "x,y = next(iter(dataset_test))\n",
    "print(x.shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次\n",
    "# for x,y in dataset_test:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入预训练的resnet50模型\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3))\n",
    "# 设置输入\n",
    "inputs = Input((height,width,3))\n",
    "# 使用resnet50进行特征提取\n",
    "x = resnet50(inputs)\n",
    "# 平均池化\n",
    "x = GlobalAvgPool2D()(x)\n",
    "# 把验证码识别的4个字符看成是4个不同的任务\n",
    "# 每个任务负责识别1个字符\n",
    "# 任务1识别第1个字符，任务2识别第2个字符，任务3识别第3个字符，任务4识别第4个字符\n",
    "x0 = Dense(num_classes, activation='softmax', name='out0')(x)\n",
    "x1 = Dense(num_classes, activation='softmax', name='out1')(x)\n",
    "x2 = Dense(num_classes, activation='softmax', name='out2')(x)\n",
    "x3 = Dense(num_classes, activation='softmax', name='out3')(x)\n",
    "# 定义模型\n",
    "model = Model(inputs, [x0,x1,x2,x3])\n",
    "# 画图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4个任务我们可以定义4个loss\n",
    "# loss_weights可以用来设置不同任务的权重，验证码识别的4个任务权重都一样\n",
    "model.compile(loss={'out0':'categorical_crossentropy',\n",
    "                    'out1':'categorical_crossentropy',\n",
    "                    'out2':'categorical_crossentropy',\n",
    "                    'out3':'categorical_crossentropy'},\n",
    "              loss_weights={'out0':1,\n",
    "                            'out1':1,\n",
    "                            'out2':1,\n",
    "                            'out3':1},\n",
    "              optimizer=SGD(lr=1e-2,momentum=0.9),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# 监控指标统一使用val_loss\n",
    "# 可以使用EarlyStopping来让模型停止，连续6个周期val_loss没有下降就结束训练\n",
    "# CSVLogger保存训练数据\n",
    "# ModelCheckpoint保存所有训练周期中val_loss最低的模型\n",
    "# ReduceLROnPlateau学习率调整策略，连续3个周期val_loss没有下降当前学习率乘以0.1\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),\n",
    "             CSVLogger('Captcha_tfdata.csv'), \n",
    "             ModelCheckpoint('Best_Captcha_tfdata.h5', monitor='val_loss', save_best_only=True),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170/170 [==============================] - 665s 4s/step - loss: 15.8797 - out0_loss: 3.2917 - out1_loss: 4.1902 - out2_loss: 4.1969 - out3_loss: 4.2008 - out0_acc: 0.1538 - out1_acc: 0.0160 - out2_acc: 0.0162 - out3_acc: 0.0176 - val_loss: 16.5250 - val_out0_loss: 4.1387 - val_out1_loss: 4.1283 - val_out2_loss: 4.1287 - val_out3_loss: 4.1293 - val_out0_acc: 0.0173 - val_out1_acc: 0.0173 - val_out2_acc: 0.0173 - val_out3_acc: 0.0246\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 655s 4s/step - loss: 13.6218 - out0_loss: 2.6112 - out1_loss: 3.8749 - out2_loss: 3.7861 - out3_loss: 3.3496 - out0_acc: 0.3083 - out1_acc: 0.0649 - out2_acc: 0.0717 - out3_acc: 0.1577 - val_loss: 18.6339 - val_out0_loss: 4.7103 - val_out1_loss: 4.3234 - val_out2_loss: 4.4678 - val_out3_loss: 5.1325 - val_out0_acc: 0.0137 - val_out1_acc: 0.0146 - val_out2_acc: 0.0173 - val_out3_acc: 0.0128\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 666s 4s/step - loss: 7.2002 - out0_loss: 1.9696 - out1_loss: 2.1001 - out2_loss: 2.1169 - out3_loss: 1.0136 - out0_acc: 0.4989 - out1_acc: 0.4104 - out2_acc: 0.4007 - out3_acc: 0.6647 - val_loss: 20.5761 - val_out0_loss: 5.5630 - val_out1_loss: 4.2817 - val_out2_loss: 4.4603 - val_out3_loss: 6.2711 - val_out0_acc: 0.0173 - val_out1_acc: 0.0128 - val_out2_acc: 0.0228 - val_out3_acc: 0.0301\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 649s 4s/step - loss: 3.2603 - out0_loss: 1.2493 - out1_loss: 0.7859 - out2_loss: 0.7820 - out3_loss: 0.4431 - out0_acc: 0.6776 - out1_acc: 0.7564 - out2_acc: 0.7568 - out3_acc: 0.8447 - val_loss: 15.8986 - val_out0_loss: 6.2944 - val_out1_loss: 3.0707 - val_out2_loss: 2.8212 - val_out3_loss: 3.7122 - val_out0_acc: 0.0830 - val_out1_acc: 0.2609 - val_out2_acc: 0.2838 - val_out3_acc: 0.1870\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 662s 4s/step - loss: 1.7783 - out0_loss: 0.7317 - out1_loss: 0.4048 - out2_loss: 0.3867 - out3_loss: 0.2551 - out0_acc: 0.7989 - out1_acc: 0.8713 - out2_acc: 0.8781 - out3_acc: 0.9123 - val_loss: 9.8881 - val_out0_loss: 6.5849 - val_out1_loss: 1.2266 - val_out2_loss: 1.2370 - val_out3_loss: 0.8396 - val_out0_acc: 0.1661 - val_out1_acc: 0.6332 - val_out2_acc: 0.6341 - val_out3_acc: 0.7427\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 665s 4s/step - loss: 1.0836 - out0_loss: 0.4535 - out1_loss: 0.2380 - out2_loss: 0.2323 - out3_loss: 0.1598 - out0_acc: 0.8713 - out1_acc: 0.9292 - out2_acc: 0.9283 - out3_acc: 0.9462 - val_loss: 5.6078 - val_out0_loss: 3.3962 - val_out1_loss: 0.6813 - val_out2_loss: 0.8791 - val_out3_loss: 0.6513 - val_out0_acc: 0.4352 - val_out1_acc: 0.7947 - val_out2_acc: 0.7372 - val_out3_acc: 0.8120\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 679s 4s/step - loss: 0.6451 - out0_loss: 0.2399 - out1_loss: 0.1502 - out2_loss: 0.1507 - out3_loss: 0.1042 - out0_acc: 0.9320 - out1_acc: 0.9546 - out2_acc: 0.9517 - out3_acc: 0.9667 - val_loss: 3.2320 - val_out0_loss: 1.5904 - val_out1_loss: 0.6818 - val_out2_loss: 0.6138 - val_out3_loss: 0.3460 - val_out0_acc: 0.6442 - val_out1_acc: 0.8029 - val_out2_acc: 0.8193 - val_out3_acc: 0.8942\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 647s 4s/step - loss: 0.3655 - out0_loss: 0.1322 - out1_loss: 0.0818 - out2_loss: 0.0854 - out3_loss: 0.0662 - out0_acc: 0.9613 - out1_acc: 0.9773 - out2_acc: 0.9737 - out3_acc: 0.9795 - val_loss: 2.7796 - val_out0_loss: 1.0650 - val_out1_loss: 0.6921 - val_out2_loss: 0.6218 - val_out3_loss: 0.4008 - val_out0_acc: 0.7746 - val_out1_acc: 0.8011 - val_out2_acc: 0.8148 - val_out3_acc: 0.8686\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 648s 4s/step - loss: 0.2558 - out0_loss: 0.0945 - out1_loss: 0.0588 - out2_loss: 0.0590 - out3_loss: 0.0434 - out0_acc: 0.9750 - out1_acc: 0.9839 - out2_acc: 0.9834 - out3_acc: 0.9873 - val_loss: 1.8819 - val_out0_loss: 0.6185 - val_out1_loss: 0.4695 - val_out2_loss: 0.5216 - val_out3_loss: 0.2723 - val_out0_acc: 0.8759 - val_out1_acc: 0.8577 - val_out2_acc: 0.8440 - val_out3_acc: 0.9197\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 647s 4s/step - loss: 0.1773 - out0_loss: 0.0654 - out1_loss: 0.0392 - out2_loss: 0.0397 - out3_loss: 0.0330 - out0_acc: 0.9842 - out1_acc: 0.9905 - out2_acc: 0.9892 - out3_acc: 0.9913 - val_loss: 1.8158 - val_out0_loss: 0.6454 - val_out1_loss: 0.4415 - val_out2_loss: 0.4884 - val_out3_loss: 0.2406 - val_out0_acc: 0.9252 - val_out1_acc: 0.8723 - val_out2_acc: 0.8641 - val_out3_acc: 0.9188\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 671s 4s/step - loss: 0.1417 - out0_loss: 0.0623 - out1_loss: 0.0273 - out2_loss: 0.0292 - out3_loss: 0.0229 - out0_acc: 0.9869 - out1_acc: 0.9950 - out2_acc: 0.9945 - out3_acc: 0.9946 - val_loss: 2.1419 - val_out0_loss: 0.6817 - val_out1_loss: 0.5320 - val_out2_loss: 0.5464 - val_out3_loss: 0.3818 - val_out0_acc: 0.8969 - val_out1_acc: 0.8641 - val_out2_acc: 0.8568 - val_out3_acc: 0.9015\n",
      "Epoch 12/100\n",
      " 32/170 [====>.........................] - ETA: 8:57 - loss: 0.1083 - out0_loss: 0.0562 - out1_loss: 0.0212 - out2_loss: 0.0155 - out3_loss: 0.0154 - out0_acc: 0.9854 - out1_acc: 0.9956 - out2_acc: 0.9971 - out3_acc: 0.9956"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b15a713a1c10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 把之前定义的dataset_train和dataset_test传入进行训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit(x=dataset_train,\n\u001b[0m\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "# 把之前定义的dataset_train和dataset_test传入进行训练\n",
    "model.fit(x=dataset_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=dataset_test,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
